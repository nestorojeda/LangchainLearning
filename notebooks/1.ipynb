{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # This loads variables from .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your setup by running a simple script that prints out the OpenAI API key (without exposing it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your API Key is set: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Your API Key is set:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building a basic chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Text: niahCgnaL olleH\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import TransformChain\n",
    "\n",
    "# Define a simple function that reverses a string as an example.\n",
    "def reverse_text(text: str) -> str:\n",
    "    return text[::-1]\n",
    "\n",
    "# Create a transform function\n",
    "def transform_func(inputs):\n",
    "    text = inputs[\"text\"]\n",
    "    return {\"output\": reverse_text(text)}\n",
    "\n",
    "# Create a chain that uses this function\n",
    "class ReverseChain(TransformChain):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            input_variables=[\"text\"],\n",
    "            output_variables=[\"output\"],\n",
    "            transform=transform_func\n",
    "        )\n",
    "\n",
    "# Instantiate and test the chain\n",
    "chain = ReverseChain()\n",
    "result = chain({\"text\": \"Hello LangChain\"})\n",
    "print(\"Reversed Text:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Response: Okay, here's a fun fact about LangChain:\n",
      "\n",
      "**LangChain was initially created as a \"proof of concept\" to demonstrate the potential of combining Large Language Models (LLMs) with other components like data sources and memory.** \n",
      "\n",
      "Initially, it was a small, experimental project built by Transparency AI (now part of Microsoft) to show how you could build sophisticated applications using LLMs – things like chatbots that could actually *remember* previous conversations and access external knowledge.  It quickly gained traction and evolved into the robust framework we know today!\n",
      "\n",
      "---\n",
      "\n",
      "**Want to know another fun fact, or would you like me to tell you a bit more about LangChain itself?**\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Create an Ollama LLM instance\n",
    "llm = OllamaLLM(model=\"gemma3:4b\")\n",
    "\n",
    "\n",
    "# Define a simple prompt and get a completion\n",
    "prompt = \"Tell me a fun fact about LangChain.\"\n",
    "response = llm(prompt)\n",
    "print(\"OpenAI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Prompt: Translate the following English text to French: How are you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt template with variables\n",
    "template = \"Translate the following English text to French: {text}\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "\n",
    "# Format the prompt with your input text\n",
    "formatted_prompt = prompt.format(text=\"How are you today?\")\n",
    "print(\"Formatted Prompt:\", formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi, who are you?\n",
      "Assistant: Hi there! I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! I can take text and images as inputs and I output text. Pretty neat, huh?\n",
      "User: Can you remind me what we talked about?\n",
      "Assistant: Okay, let’s see! Just a moment… We just had a conversation where you asked me who I am, and I told you I’m Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model and I can take text and images as inputs and output text. Does that jog your memory?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Create a conversation chain with memory\n",
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "# Simulate a conversation\n",
    "print(\"User: Hi, who are you?\")\n",
    "response = conversation.predict(input=\"Hi, who are you?\")\n",
    "print(\"Assistant:\", response)\n",
    "\n",
    "print(\"User: Can you remind me what we talked about?\")\n",
    "response = conversation.predict(input=\"Can you remind me what we talked about?\")\n",
    "print(\"Assistant:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
